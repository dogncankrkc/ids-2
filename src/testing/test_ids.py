"""
IDS â€“ Standalone Test Script
----------------------------
Bu dosya eÄŸitim yapmaz. Sadece diske kaydedilmiÅŸ "best_model.pth"
ve "test_split_saved.csv" dosyalarÄ±nÄ± yÃ¼kleyerek final performans
ve hÄ±z (latency) testlerini gerÃ§ekleÅŸtirir.
"""

import os
import sys

# ==========================================
# PATH DÃœZELTME (IMPORT HATASINI Ã‡Ã–ZER)
# ==========================================
# Scriptin bulunduÄŸu klasÃ¶rden iki adÄ±m geriye (proje kÃ¶k dizinine) git
# ve Python'un arama yollarÄ±na ekle.
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../.."))
sys.path.append(project_root)

# ==========================================
# IMPORTLAR (PATH EKLENDÄ°KTEN SONRA)
# ==========================================
import torch
import joblib
import yaml
import pandas as pd
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import confusion_matrix

# Kendi modÃ¼llerini import et
from src.models.cnn_model import create_ids_model
from src.training.trainer import Trainer
from src.utils.visualization import plot_confusion_matrix
from src.utils.helpers import get_device

# ==============================
# AYARLAR (CONFIG)
# ==============================
# Dosya yollarÄ±nÄ± proje kÃ¶k dizinine gÃ¶re dinamik yapÄ±yoruz
CONFIG_PATH = os.path.join(project_root, "configs/multiclass_config.yaml")
TEST_DATA_PATH = os.path.join(project_root, "data/processed/test_split_saved.csv")
ENCODER_PATH = os.path.join(project_root, "models/label_encoder.pkl")
OUTPUT_DIR = os.path.join(project_root, "outputs/test_results")
CHECKPOINT_DIR = os.path.join(project_root, "models/checkpoints/ids_multiclass")

# EÄŸer config dosyasÄ±ndan okuyamazsa default deÄŸerler
DEFAULT_BATCH_SIZE = 128
MODE = "multiclass"  # 'binary' veya 'multiclass'

def load_config(path):
    if os.path.exists(path):
        with open(path, "r") as f:
            return yaml.safe_load(f)
    print(f"[WARN] Config bulunamadÄ±: {path}, varsayÄ±lanlar kullanÄ±lacak.")
    return {}

def main():
    # 1. HazÄ±rlÄ±k
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    device = get_device()
    config = load_config(CONFIG_PATH)
    
    # Config'den deÄŸerleri al veya default kullan
    batch_size = config.get("data", {}).get("batch_size", DEFAULT_BATCH_SIZE)
    # Config dosyasÄ±ndaki path gÃ¶receli olabilir, biz yukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z CHECKPOINT_DIR'i kullanalÄ±m
    model_path = os.path.join(CHECKPOINT_DIR, "best_model.pth")

    print(f"\n[INFO] Device: {device}")
    print(f"[INFO] Model Path: {model_path}")
    print(f"[INFO] Test Data: {TEST_DATA_PATH}")

    # 2. Label Encoder YÃ¼kle (SÄ±nÄ±f isimleri iÃ§in)
    if os.path.exists(ENCODER_PATH):
        encoder = joblib.load(ENCODER_PATH)
        classes = encoder.classes_
        num_classes = len(classes)
        inv_label_map = {i: label for i, label in enumerate(classes)}
        print(f"[INFO] SÄ±nÄ±flar yÃ¼klendi: {num_classes} adet")
    else:
        # Encoder yoksa manuel fallback
        print("[WARN] Label encoder bulunamadÄ±, varsayÄ±lan sÄ±nÄ±flar atanÄ±yor.")
        num_classes = 2 if MODE == "binary" else 8
        inv_label_map = {i: str(i) for i in range(num_classes)}
        classes = list(inv_label_map.values())

    # 3. Test Verisini YÃ¼kle
    if not os.path.exists(TEST_DATA_PATH):
        raise FileNotFoundError(f"Test verisi bulunamadÄ±: {TEST_DATA_PATH}")
    
    df_test = pd.read_csv(TEST_DATA_PATH)
    
    # Veriyi Tensor'a Ã§evir
    X_np = df_test.drop(columns=["label"]).values
    y_np = df_test["label"].values

    X_test = torch.tensor(X_np, dtype=torch.float32)
    y_test = torch.tensor(y_np, dtype=torch.long)

    # Model 1D CNN ise boyut ekle: (Batch, Features) -> (Batch, 1, Features)
    if X_test.ndim == 2:
        X_test = X_test.unsqueeze(1) 

    test_dataset = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    print(f"[INFO] Test veri seti hazÄ±r: {len(test_dataset)} Ã¶rnek")

    # 4. Modeli OluÅŸtur ve AÄŸÄ±rlÄ±klarÄ± YÃ¼kle
    model = create_ids_model(mode=MODE, num_classes=num_classes)
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model dosyasÄ± yok: {model_path} - Ã–nce eÄŸitim yapÄ±n.")
        
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    print("[INFO] Model baÅŸarÄ±yla yÃ¼klendi.")

    # 5. Trainer ile Test (Trainer sÄ±nÄ±fÄ±ndaki test fonksiyonunu kullanÄ±yoruz)
    trainer = Trainer(
        model=model,
        criterion=nn.CrossEntropyLoss(), # Test iÃ§in zorunlu deÄŸil ama bulunsun
        optimizer=torch.optim.Adam(model.parameters()), # Dummy
        device=device,
        checkpoint_dir=CHECKPOINT_DIR
    )

    print("\n" + "="*40)
    print("ðŸš€ BAÅžLATILIYOR: LATENCY VE PERFORMANS TESTÄ°")
    print("="*40)
    
    # Trainer iÃ§indeki test metodunu Ã§aÄŸÄ±r
    results = trainer.test(test_loader)

    # SonuÃ§larÄ± YAML olarak kaydet
    results_path = os.path.join(OUTPUT_DIR, "final_metrics.yaml")
    with open(results_path, "w") as f:
        yaml.safe_dump(results, f)
    print(f"[SAVE] Metrikler kaydedildi: {results_path}")

    # 6. DetaylÄ± Analiz: Confusion Matrix ve CSV Ã‡Ä±ktÄ±sÄ±
    print("\n[INFO] DetaylÄ± tahminler ve Confusion Matrix hazÄ±rlanÄ±yor...")
    
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(targets.numpy())

    # CSV Kaydet
    results_df = pd.DataFrame({
        "True_Label_ID": all_targets,
        "Pred_Label_ID": all_preds,
        "True_Label_Name": [inv_label_map.get(i, str(i)) for i in all_targets],
        "Pred_Label_Name": [inv_label_map.get(i, str(i)) for i in all_preds]
    })
    results_df["Is_Correct"] = results_df["True_Label_ID"] == results_df["Pred_Label_ID"]
    
    csv_path = os.path.join(OUTPUT_DIR, "predictions.csv")
    results_df.to_csv(csv_path, index=False)
    print(f"[SAVE] Tahmin detaylarÄ± CSV: {csv_path}")

    # Confusion Matrix Ã‡iz
    cm = confusion_matrix(all_targets, all_preds)
    
    plot_confusion_matrix(
        cm, 
        class_names=classes, 
        save_path=os.path.join(OUTPUT_DIR, "confusion_matrix_norm.png"),
        normalize=True
    )
    
    plot_confusion_matrix(
        cm, 
        class_names=classes, 
        save_path=os.path.join(OUTPUT_DIR, "confusion_matrix_count.png"),
        normalize=False
    )
    
    print(f"[SAVE] Confusion matrix gÃ¶rselleri kaydedildi: {OUTPUT_DIR}")
    print("\nâœ… TEST Ä°ÅžLEMÄ° TAMAMLANDI.")

if __name__ == "__main__":
    main()