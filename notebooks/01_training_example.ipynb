{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS — Tabular → CNN Training Example\n",
    "\n",
    "This notebook demonstrates training the project's CNN on the tabular IDS dataset\n",
    "(preprocessing → DataLoader → model → trainer → evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project imports and setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Project modules\n",
    "from src.data.dataset import load_raw_csv\n",
    "from src.data.preprocess import preprocess_multiclass, preprocess_binary, preprocess_single_sample\n",
    "from src.models.cnn_model import create_ids_model\n",
    "from src.training.trainer import Trainer\n",
    "from src.training.metrics import accuracy, confusion_matrix\n",
    "from src.utils.helpers import set_seed, get_device, get_optimizer, get_scheduler\n",
    "from src.utils.visualization import plot_training_history, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility and device\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print('Device:', device)\n",
    "\n",
    "# Quick config for the notebook (tweak as needed)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 5e-4\n",
    "MODE = 'multiclass'  # 'binary' or 'multiclass'\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CSVs from data/raw/ (concatenates files)\n",
    "df = load_raw_csv(data_dir='data/raw')\n",
    "print('Loaded dataframe with rows:', len(df))\n",
    "\n",
    "# Choose preprocessing based on MODE\n",
    "if MODE == 'binary':\n",
    "    X_train, X_val, y_train, y_val = preprocess_binary(df, test_size=TEST_SIZE)\n",
    "    num_classes = 2\n",
    "else:\n",
    "    X_train, X_val, y_train, y_val = preprocess_multiclass(df, test_size=TEST_SIZE)\n",
    "    num_classes = int(np.max(y_train) + 1) if len(np.unique(y_train)) > 1 else None\n",
    "\n",
    "# Convert to torch tensors and reshape to (N, C, H, W)\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_ds = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Train samples:', len(train_ds))\n",
    "print('Val samples:', len(val_ds))\n",
    "print('Num classes:', num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDS model (factory handles binary/multiclass)\n",
    "if MODE == 'binary':\n",
    "    model = create_ids_model(mode='binary', num_classes=2)\n",
    "else:\n",
    "    if num_classes is None:\n",
    "        raise ValueError('num_classes could not be inferred from labels')\n",
    "    model = create_ids_model(mode='multiclass', num_classes=num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'Model: {model.__class__.__name__}')\n",
    "print(f'Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = get_optimizer(model=model, optimizer_name='adamw', learning_rate=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = get_scheduler(optimizer=optimizer, scheduler_name='cosine', epochs=EPOCHS)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    checkpoint_dir='models/checkpoints/notebook',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    early_stopping_patience=8,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        preds = out.argmax(dim=1).cpu()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(yb.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "acc = accuracy(all_preds, all_targets)\n",
    "print(f'Validation Accuracy: {acc:.2f}%')\n",
    "\n",
    "# Confusion matrix (numpy) and plot\n",
    "cm = confusion_matrix(all_preds, all_targets, num_classes=num_classes)\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Save final model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model weights into models/final/\n",
    "import os\n",
    "os.makedirs('models/final', exist_ok=True)\n",
    "torch.save({'model_state_dict': model.state_dict()}, 'models/final/final_model_notebook.pth')\n",
    "print('Saved models/final/final_model_notebook.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
